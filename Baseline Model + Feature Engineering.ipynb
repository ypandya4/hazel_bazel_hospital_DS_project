{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91d16f2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fff49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import math\n",
    "import requests\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "from uuid import uuid4\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bacc6b7",
   "metadata": {},
   "source": [
    "# Custom transformer imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb32c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP preprocessor which assigns categories and compresses some code\n",
    "from custom_transformers.preprocessor import ColumnConverter\n",
    "\n",
    "# WIP ordinal category preprocessor\n",
    "from custom_transformers.custom_ordinal_encoder import custom_oe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da63fd8",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4102f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    df = pd.read_csv(os.path.join(\"data\", \"train_data.csv\"))\n",
    "    return df\n",
    "\n",
    "data_train = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ec538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_index(df, indexcol: str):\n",
    "    _df = df.copy()\n",
    "    _df = _df.set_index(indexcol)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d93026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_categorical(df, column_list: []):\n",
    "    _df = df.copy()\n",
    "    for column in column_list:\n",
    "        _df[column] = _df[column].astype('category')\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66624bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_unordered_categorical(df, column_list: []):\n",
    "    _df = df.copy()\n",
    "    ohe = ce.OneHotEncoder(verbose=1,\n",
    "                           cols=column_list,\n",
    "                           handle_missing=\"indicator\",\n",
    "                           use_cat_names=True)\n",
    "    _df = ohe.fit_transform(_df)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "027b67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarymap(df):\n",
    "    _df = df.copy()\n",
    "    _df = _df.assign(has_prosthesis = _df['has_prosthesis'].map({True: 1, False: 0}),\n",
    "                     blood_transfusion = _df['blood_transfusion'].map({True: 1, False: 0}),\n",
    "                     diuretics = _df['diuretics'].map({'Yes': 1, 'No': 0}),\n",
    "                     insulin = _df['insulin'].map({'Yes': 1, 'No': 0}),\n",
    "                     change = _df['change'].map({'Ch': 1, 'No': 0}),\n",
    "                     diabetesMed = _df['diabetesMed'].map({'Yes': 1, 'No': 0}))\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3950d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ordered_cats(df):\n",
    "    _df = df.copy()\n",
    "    # some string operations\n",
    "    _df['age'] = _df['age'].str.lstrip(\"\\[\").str.rstrip(\")\")\n",
    "    _df['weight'] = _df['weight'].str.lstrip(\"\\[\").str.rstrip(\")\")\n",
    "    _df['max_glu_serum'] = _df['max_glu_serum'].str.lower()\n",
    "    _df['A1Cresult'] = _df['A1Cresult'].str.lower()\n",
    "    \n",
    "    #making it categorical\n",
    "    _df = assign_categorical(_df, ['age', 'weight', 'max_glu_serum', 'A1Cresult'])\n",
    "    \n",
    "    #setting categories and replacing missing or unexpected values with 'unknown'\n",
    "    ordered_age = ['unknown',\n",
    "                   '0-10',\n",
    "                   '10-20',\n",
    "                   '20-30',\n",
    "                   '30-40',\n",
    "                   '40-50',\n",
    "                   '50-60',\n",
    "                   '60-70',\n",
    "                   '70-80',\n",
    "                   '80-90',\n",
    "                   '90-100']\n",
    "    _df = _df.assign(age=_df['age'].cat.set_categories(ordered_age, ordered=True))\n",
    "    _df.loc[~(_df['age'].isin(ordered_age)), 'age'] = 'unknown'\n",
    "    \n",
    "    ordered_weight = ['unknown',\n",
    "                      '0-25',\n",
    "                      '25-50',\n",
    "                      '50-75',\n",
    "                      '75-100',\n",
    "                      '100-125',\n",
    "                      '125-150',\n",
    "                      '150-175',\n",
    "                      '175-200',\n",
    "                      '>200']\n",
    "    _df = _df.assign(weight=_df['weight'].cat.set_categories(ordered_weight, ordered=True))\n",
    "    _df.loc[~(_df['weight'].isin(ordered_weight)), 'weight'] = 'unknown'\n",
    "    \n",
    "    ordered_max_glu = ['unknown',\n",
    "                       'norm',\n",
    "                       '>200',\n",
    "                       '>300']\n",
    "    _df = _df.assign(max_glu_serum=_df['max_glu_serum'].cat.set_categories(ordered_max_glu, ordered=True))\n",
    "    _df.loc[~(_df['max_glu_serum'].isin(ordered_max_glu)), 'max_glu_serum'] = 'unknown'\n",
    "\n",
    "    ordered_A1C = ['unknown',\n",
    "                   'norm',\n",
    "                   '>7',\n",
    "                   '>8']\n",
    "    _df = _df.assign(A1Cresult=_df['A1Cresult'].cat.set_categories(ordered_A1C, ordered=True))\n",
    "    _df.loc[~(_df['A1Cresult'].isin(ordered_A1C)), 'A1Cresult'] = 'unknown'\n",
    "    \n",
    "    return _df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaaf75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target(df, target: str):\n",
    "    _df = df.copy()\n",
    "    _df[target] = np.where(_df[target]== 'Yes', True, False)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e552ae",
   "metadata": {},
   "source": [
    "# Custom Transformers and pipeline objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c4664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DroppingColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=[]):\n",
    "        self.cols = cols\n",
    "    def fit(self, X=None, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        X = data.copy()\n",
    "        X = X.drop(self.cols,axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d6962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=[]):\n",
    "        self.cols = cols\n",
    "    def fit(self, X=None, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        X = data.copy()\n",
    "        X = X[self.cols]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08c64d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryProcessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X=None, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        X = data.copy()\n",
    "        X = binarymap(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fcba0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignCategorical(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=[]):\n",
    "        self.cols = cols\n",
    "    def fit(self, X=None, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        X = data.copy()\n",
    "        X = assign_categorical(X, column_list=self.cols)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "367dc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ordinal_cat_prep(BaseEstimator, TransformerMixin):\n",
    "      \n",
    "    def fit(self, X=None, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        X = data.copy()\n",
    "        X = process_ordered_cats(X)\n",
    "        \n",
    "        orde = ce.OrdinalEncoder(verbose=1,\n",
    "                        cols=['age',\n",
    "                               'weight',\n",
    "                               'max_glu_serum',\n",
    "                               'A1Cresult',\n",
    "                               'complete_vaccination_status'],\n",
    "                         handle_unknown='value',\n",
    "                         handle_missing='value',\n",
    "                         mapping = [{'col': 'age', 'mapping': {'0-10':1,\n",
    "                                                               '10-20':2,\n",
    "                                                               '20-30':3,\n",
    "                                                               '30-40':4,\n",
    "                                                               '40-50':5,\n",
    "                                                               '50-60':6,\n",
    "                                                               '60-70':7,\n",
    "                                                               '70-80':8,\n",
    "                                                               '80-90':9,\n",
    "                                                               '90-100':10}},\n",
    "        \n",
    "                                    {'col': 'weight', 'mapping': {'0-25':1,\n",
    "                                                                  '25-50':2, \n",
    "                                                                  '50-75':3,\n",
    "                                                                  '75-100':4,\n",
    "                                                                  '100-125':5, \n",
    "                                                                  '125-150':6, \n",
    "                                                                  '150-175':7, \n",
    "                                                                  '175-200':8, \n",
    "                                                                  '>200':9}},\n",
    "                                    \n",
    "                                    {'col': 'max_glu_serum', 'mapping': {'norm':1,\n",
    "                                                                         '>200':2,\n",
    "                                                                         '>300':3,}},\n",
    "                                    \n",
    "                                    {'col': 'A1Cresult', 'mapping': {'norm':1,\n",
    "                                                                         '>7':2,\n",
    "                                                                         '>8':3,}},\n",
    "                                   \n",
    "                                    {'col': 'complete_vaccination_status', 'mapping': {'Complete':1,\n",
    "                                                                                       'Incomplete':0}}])\n",
    "                                          \n",
    "        return orde.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97871020",
   "metadata": {},
   "source": [
    "# Simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "517e7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'readmitted'\n",
    "index_col = 'admission_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "787600aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_train_data()\n",
    "data_train = assign_index(data_train, index_col)\n",
    "data_train = build_target(data_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e51f32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all features (n=numerical, uc=unordered actegory, oc=ordered category, b=boolean)\n",
    "\n",
    "all_features = ['patient_id', #identifier\n",
    "                'race', #uc\n",
    "                'gender', #uc\n",
    "                'age', #oc\n",
    "                'weight', #oc               \n",
    "                'admission_type_code', #uc\n",
    "                'discharge_disposition_code', #uc\n",
    "                'admission_source_code', #uc\n",
    "                'time_in_hospital', #n\n",
    "                'payer_code', #uc\n",
    "                'medical_specialty', #uc\n",
    "                'has_prosthesis', #b\n",
    "                'complete_vaccination_status', #uc\n",
    "                'num_lab_procedures', #n\n",
    "                'num_procedures', #n\n",
    "                'num_medications', #n\n",
    "                'number_outpatient', #n\n",
    "                'number_emergency', #n\n",
    "                'number_inpatient', #n\n",
    "                'diag_1', #uc\n",
    "                'diag_2', #uc\n",
    "                'diag_3', #uc\n",
    "                'number_diagnoses', #n\n",
    "                'blood_type', #uc\n",
    "                'hemoglobin_level', #n\n",
    "                'blood_transfusion', #b\n",
    "                'max_glu_serum', #oc\n",
    "                'A1Cresult', #oc\n",
    "                'diuretics', #b\n",
    "                'insulin', #b\n",
    "                'change', #b\n",
    "                'diabetesMed'] #b]\n",
    "\n",
    "num_features = ['time_in_hospital', \n",
    "                'num_lab_procedures',\n",
    "                'num_procedures',\n",
    "                'num_medications',\n",
    "                'number_outpatient',\n",
    "                'number_emergency',\n",
    "                'number_inpatient',\n",
    "                'number_diagnoses',\n",
    "                'hemoglobin_level']\n",
    "\n",
    "bool_features = ['has_prosthesis',\n",
    "                 'blood_transfusion',\n",
    "                 'diuretics',\n",
    "                 'insulin',\n",
    "                 'change',\n",
    "                 'diabetesMed']\n",
    "\n",
    "cat_features = ['race',\n",
    "                'gender',\n",
    "                'admission_type_code', \n",
    "                'discharge_disposition_code',\n",
    "                'admission_source_code', \n",
    "                'payer_code',\n",
    "                'medical_specialty',\n",
    "                'diag_1',\n",
    "                'diag_2',\n",
    "                'diag_3',\n",
    "                'blood_type']\n",
    "\n",
    "ord_cat_features = ['age',\n",
    "                    'weight',\n",
    "                    'max_glu_serum',\n",
    "                    'A1Cresult',\n",
    "                    'complete_vaccination_status',]\n",
    "\n",
    "# missing features: date of admission and date of release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cdd6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to boolean\n",
    "df_train, df_test = train_test_split(data_train, test_size=0.2, random_state=42, stratify=data_train[target])\n",
    "X_train = df_train.drop(target, axis=1)\n",
    "y_train = df_train[target]\n",
    "X_test = df_test.drop(target, axis=1)\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2caf2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['time_in_hospital', \n",
    "                     'num_lab_procedures',\n",
    "                     'num_procedures',\n",
    "                     'num_medications',\n",
    "                     'number_outpatient',\n",
    "                     'number_emergency',\n",
    "                     'number_inpatient',\n",
    "                     'number_diagnoses',\n",
    "                     'hemoglobin_level',\n",
    "                     \n",
    "                     'has_prosthesis',\n",
    "                     'blood_transfusion',\n",
    "                     'diuretics',\n",
    "                     'insulin',\n",
    "                     'change',\n",
    "                     'diabetesMed',\n",
    "                     \n",
    "                     'race',\n",
    "                     'gender',\n",
    "                     'admission_type_code', \n",
    "                     'discharge_disposition_code',\n",
    "                     'admission_source_code', \n",
    "                     'payer_code',\n",
    "                     'medical_specialty',\n",
    "                     'complete_vaccination_status',\n",
    "                     'blood_type',\n",
    "                     \n",
    "                     'max_glu_serum',\n",
    "                     'A1Cresult',\n",
    "                     'age',\n",
    "                     'weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7365df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = [feat for feat in selected_features if feat in num_features]\n",
    "cat_feats = [feat for feat in selected_features if feat in cat_features+bool_features+ord_cat_features]\n",
    "bool_feats = [feat for feat in selected_features if feat in bool_features]\n",
    "ord_cat_feats = [feat for feat in selected_features if feat in ord_cat_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566aed0",
   "metadata": {},
   "source": [
    "# Pipeline 1 - just numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3f00e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['time_in_hospital', \n",
    "                'num_lab_procedures',\n",
    "                'num_procedures',\n",
    "                'num_medications',\n",
    "                'number_outpatient',\n",
    "                'number_emergency',\n",
    "                'number_inpatient',\n",
    "                'number_diagnoses',\n",
    "                'hemoglobin_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cd2fc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23879680785758134\n",
      "0.4288864388092613\n",
      "0.16546150574223734\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    SelectColumns(cols=num_feats),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    RandomForestClassifier(max_depth=10, class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# To use on other cells\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7d70e",
   "metadata": {},
   "source": [
    "# Pipeline 2 - adding the binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fae7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_features = ['has_prosthesis',\n",
    "                 'blood_transfusion',\n",
    "                 'diuretics',\n",
    "                 'insulin',\n",
    "                 'change',\n",
    "                 'diabetesMed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5f58f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24461091576211585\n",
      "0.4410143329658214\n",
      "0.16924053310767928\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    SelectColumns(cols=num_feats+bool_feats),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    RandomForestClassifier(max_depth=10, class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# To use on other cells\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff16d0",
   "metadata": {},
   "source": [
    "# Pipeline 3 - adding ordered categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a4fc2",
   "metadata": {},
   "source": [
    "1. added age, weight, max_glu_serum, A1Cresult, and also encoded vaccination status here\n",
    "2. also did some playing around with the model options for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a351b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_cat_features = ['age',\n",
    "                    'weight',\n",
    "                    'max_glu_serum',\n",
    "                    'A1Cresult',\n",
    "                    'complete_vaccination_status',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5215a0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2468948803392911\n",
      "0.4492833517089305\n",
      "0.1702172096908939\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    custom_oe(),\n",
    "    SelectColumns(cols=num_feats+bool_feats+ord_cat_feats),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    RandomForestClassifier(max_depth=10, class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# To use on other cells\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bba43e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01953336950623983\n",
      "0.009922822491730982\n",
      "0.6206896551724138\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    custom_oe(),\n",
    "    SelectColumns(cols=num_feats+bool_feats+ord_cat_feats),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    GradientBoostingClassifier(learning_rate=.1,\n",
    "                               n_estimators=100,\n",
    "                               subsample=0.2,\n",
    "                               n_iter_no_change=10,\n",
    "                               max_features = None,\n",
    "                               random_state=42)\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# To use on other cells\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63e81132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0193756727664155\n",
      "0.009922822491730982\n",
      "0.4090909090909091\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    custom_oe(),\n",
    "    SelectColumns(cols=num_feats+bool_feats+ord_cat_feats),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                                      param_grid = {'max_depth': range(1, 10),\n",
    "                                                    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                                                    #'max_features': range(1, X.shape[1]),\n",
    "                                                    'criterion': ['entropy', 'gini']},\n",
    "                                      cv=5,\n",
    "                                      scoring=\"f1\", #or should it be 'accuracy'\n",
    "                                      return_train_score=True))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# To use on other cells\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37c711",
   "metadata": {},
   "source": [
    "# Adding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eda46ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['race', #done\n",
    "                'gender', #done\n",
    "                'admission_type_code', #done \n",
    "                'discharge_disposition_code', #done\n",
    "                #'admission_source_code', \n",
    "                'payer_code', #done (now the insurance column)\n",
    "                'medical_specialty', #done (any specialty over 100 - lets see how bad it gets)\n",
    "                #'diag_1',\n",
    "                #'diag_2',\n",
    "                #'diag_3',\n",
    "                'blood_type'] #dropping blood type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29840f",
   "metadata": {},
   "source": [
    "1. Will drop blood type - too many inconsistencies and not feasible to guess\n",
    "1. Does admission type and code have a role?\n",
    "1. Race, gender can be encoded\n",
    "1. Payer code 'SP' is an indicator of uninsured patients - what to do with '?' should we make 3 categories?\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f23066",
   "metadata": {},
   "source": [
    "Processing Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8045ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processgender(df):\n",
    "    _df = df.copy()\n",
    "    _df['gender'] = _df['gender'].str.lower()\n",
    "    valid_genders = ['male', 'female']\n",
    "    _df.loc[~(_df['gender'].isin(valid_genders)), 'age'] = 'unknown'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d6d06",
   "metadata": {},
   "source": [
    "Processing Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "402e6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processrace(df):\n",
    "    _df = df.copy()\n",
    "    _df['race'] = _df['race'].str.lower().str.lstrip().str[0:3]\n",
    "    black = ['afr', 'bla']\n",
    "    white = ['cau', 'whi', 'eur']\n",
    "    hispanic = ['his', 'lat']\n",
    "    asian = ['asi']\n",
    "    race_options = black+white+hispanic+asian\n",
    "    _df.loc[~(_df['race'].isin(race_options)), 'race'] = 'unknown/other'\n",
    "    _df.loc[(_df['race'].isin(black)), 'race'] = 'black'\n",
    "    _df.loc[(_df['race'].isin(white)), 'race'] = 'white'\n",
    "    _df.loc[(_df['race'].isin(hispanic)), 'race'] = 'hispanic'\n",
    "    _df.loc[(_df['race'].isin(asian)), 'race'] = 'asian'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d719d4",
   "metadata": {},
   "source": [
    "Process insurance status and payer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25c7a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insurancestatus(df):\n",
    "    _df = testdf.copy()\n",
    "    _df.payer_code = _df.payer_code.where(_df.payer_code != '?')\n",
    "    _df.payer_code = _df.payer_code.fillna(value='unknown')\n",
    "    _df.loc[(_df['payer_code'] == 'SP'), 'payer_code'] == 'uninsured'\n",
    "    _df.loc[~(_df['payer_code'].isin(['SP', 'unknown'])), 'payer_code'] = 'insured'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b7df711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "?     25983\n",
       "MC    20620\n",
       "HM     3937\n",
       "SP     3212\n",
       "BC     2959\n",
       "MD     2278\n",
       "CP     1647\n",
       "UN     1555\n",
       "CM     1235\n",
       "OG      622\n",
       "PO      391\n",
       "DM      353\n",
       "CH      101\n",
       "WC       83\n",
       "OT       62\n",
       "MP       57\n",
       "SI       33\n",
       "FR        1\n",
       "Name: payer_code, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = X_train.copy()\n",
    "testdf.payer_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7dd4f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.payer_code=testdf.payer_code.where(testdf.payer_code != '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2ca15c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25983"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.payer_code.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b499620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = insurancestatus(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af919897",
   "metadata": {},
   "source": [
    "Processing Admission Type Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf9cef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processadmissiontype(df):\n",
    "    _df = df.copy()\n",
    "    _df.loc[(_df['admission_type_code'].isin([5, 6, 8])), 'admission_type_code'] = 'n/a'\n",
    "    _df.loc[(_df['admission_type_code'] == 1), 'admission_type_code'] = 'emergency'\n",
    "    _df.loc[(_df['admission_type_code'] == 2), 'admission_type_code'] = 'urgent'\n",
    "    _df.loc[(_df['admission_type_code'] == 3), 'admission_type_code'] = 'elective'\n",
    "    _df.loc[(_df['admission_type_code'] == 4), 'admission_type_code'] = 'newborn'\n",
    "    _df.loc[(_df['admission_type_code'] == 7), 'admission_type_code'] = 'trauma'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078f5c2",
   "metadata": {},
   "source": [
    "Processing Admission Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd80e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e9856a",
   "metadata": {},
   "source": [
    "Processing Discharge Disposition Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23f12c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processdischargecode(df):\n",
    "    _df = df.copy()\n",
    "\n",
    "    home = [1]\n",
    "    left_ama = [7]\n",
    "    hospice = [13, 14]\n",
    "    transferred = [2, 3, 4, 5, 9, 10, 15, 22, 23, 24, 27, 28, 29]\n",
    "    died = [11, 19, 20, 21]\n",
    "    for_outpatient_services = [12, 16, 17]\n",
    "    home_services = [6, 8]\n",
    "    all_cats = home+left_ama+hospice+transferred+died+for_outpatient_services+home_services\n",
    "\n",
    "    _df.loc[~(_df['discharge_disposition_code'].isin(all_cats)), 'discharge_disposition_code'] = 'unknown'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(home)), 'discharge_disposition_code'] = 'discharged_home'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(left_ama)), 'discharge_disposition_code'] = 'left_ama'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(hospice)), 'discharge_disposition_code'] = 'discharged_hospice'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(transferred)), 'discharge_disposition_code'] = 'transferred_inpatient'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(died)), 'discharge_disposition_code'] = 'expired'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(for_outpatient_services)), 'discharge_disposition_code'] = 'transferred_outpatient'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(home_services)), 'discharge_disposition_code'] = 'home_care'\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d68873",
   "metadata": {},
   "source": [
    "Process specializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1b325fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = X_train.copy()[cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3018352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processspecializations(df):\n",
    "    _df = df.copy()\n",
    "    _df['medical_specialty'] = _df['medical_specialty'].str.lower()\n",
    "    counts = pd.DataFrame(_df.medical_specialty.value_counts())\n",
    "    df_mask = counts['medical_specialty']>=100\n",
    "    selected_specialties = counts[df_mask]\n",
    "    selected_specialties = selected_specialties.index.to_list()\n",
    "    _df.loc[~(_df['medical_specialty'].isin(selected_specialties)), 'medical_specialty'] = 'other'\n",
    "    _df.loc[(_df['medical_specialty'] == '?'), 'medical_specialty'] = 'unknown'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85a8ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df=processspecializations(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9c5ded4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown                              31970\n",
       "internalmedicine                      9381\n",
       "family/generalpractice                4820\n",
       "emergency/trauma                      4779\n",
       "cardiology                            3409\n",
       "surgery-general                       1979\n",
       "nephrology                            1031\n",
       "other                                  961\n",
       "orthopedics                            860\n",
       "orthopedics-reconstructive             777\n",
       "radiologist                            714\n",
       "pulmonology                            569\n",
       "psychiatry                             537\n",
       "urology                                452\n",
       "surgery-cardiovascular/thoracic        422\n",
       "obstetricsandgynecology                420\n",
       "gastroenterology                       371\n",
       "surgery-vascular                       364\n",
       "surgery-neuro                          304\n",
       "physicalmedicineandrehabilitation      244\n",
       "oncology                               220\n",
       "pediatrics                             168\n",
       "neurology                              143\n",
       "hematology/oncology                    133\n",
       "pediatrics-endocrinology               101\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7804866",
   "metadata": {},
   "source": [
    "# A quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "273b29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = X_train.copy()\n",
    "cc = ColumnConverter()\n",
    "coe = custom_oe()\n",
    "testdf = cc.fit_transform(testdf)\n",
    "testdf = coe.fit_transform(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a447a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "caten = ce.OneHotEncoder(verbose=1, cols=cat_features, handle_missing=\"indicator\", use_cat_names=True)\n",
    "testdf = caten.fit_transform(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a61df274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_unknown/other</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>race_nan</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>blood_type_O-</th>\n",
       "      <th>blood_type_nan</th>\n",
       "      <th>hemoglobin_level</th>\n",
       "      <th>blood_transfusion</th>\n",
       "      <th>max_glu_serum</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>diuretics</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>120523950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>46605996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39818</th>\n",
       "      <td>7574652</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23698</th>\n",
       "      <td>72967194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71883</th>\n",
       "      <td>206791254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              patient_id  race_white  race_black  race_unknown/other  \\\n",
       "admission_id                                                           \n",
       "6400           120523950           1           0                   0   \n",
       "4000            46605996           0           1                   0   \n",
       "39818            7574652           0           1                   0   \n",
       "23698           72967194           1           0                   0   \n",
       "71883          206791254           1           0                   0   \n",
       "\n",
       "              race_hispanic  race_asian  race_nan  gender_male  gender_female  \\\n",
       "admission_id                                                                    \n",
       "6400                      0           0         0            1              0   \n",
       "4000                      0           0         0            0              1   \n",
       "39818                     0           0         0            0              1   \n",
       "23698                     0           0         0            0              1   \n",
       "71883                     0           0         0            0              1   \n",
       "\n",
       "              gender_unknown  ...  blood_type_O-  blood_type_nan  \\\n",
       "admission_id                  ...                                  \n",
       "6400                       0  ...              0               0   \n",
       "4000                       0  ...              0               0   \n",
       "39818                      0  ...              0               0   \n",
       "23698                      0  ...              0               0   \n",
       "71883                      0  ...              0               0   \n",
       "\n",
       "              hemoglobin_level  blood_transfusion  max_glu_serum  A1Cresult  \\\n",
       "admission_id                                                                  \n",
       "6400                      15.4                  0           -1.0        3.0   \n",
       "4000                      13.8                  0           -1.0       -1.0   \n",
       "39818                     13.6                  0           -1.0       -1.0   \n",
       "23698                     14.1                  0           -1.0       -1.0   \n",
       "71883                     13.2                  0           -1.0       -1.0   \n",
       "\n",
       "              diuretics  insulin  change  diabetesMed  \n",
       "admission_id                                           \n",
       "6400                  0        1       1            1  \n",
       "4000                  0        1       1            1  \n",
       "39818                 0        1       0            1  \n",
       "23698                 0        0       0            1  \n",
       "71883                 0        0       0            1  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ad7bc28",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['race', 'blood_type', 'payer_code', 'admission_type_code', 'medical_specialty', 'gender', 'discharge_disposition_code'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-bb8242900cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \"\"\"\n\u001b[1;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e88228a25046>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['race', 'blood_type', 'payer_code', 'admission_type_code', 'medical_specialty', 'gender', 'discharge_disposition_code'] not in index\""
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    custom_oe(),\n",
    "    ce.OneHotEncoder(verbose=1,   ### This needs to be a column transformer\n",
    "                     cols=cat_features,\n",
    "                     handle_missing=\"indicator\",\n",
    "                     use_cat_names=True),\n",
    "    SelectColumns(cols=num_feats+bool_feats+ord_cat_feats+cat_features),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    RandomForestClassifier(max_depth=10, class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# To use on other cells\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7414156a",
   "metadata": {},
   "source": [
    "# Output files (pickling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da485135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DIR = '/tmp'\n",
    "with open(os.path.join(TMP_DIR, \"columns.json\"), 'w') as fh:\n",
    "    json.dump(X_train.columns.tolist(), fh)\n",
    "\n",
    "with open(os.path.join(TMP_DIR, \"dtypes.pickle\"), 'wb') as fh:\n",
    "    pickle.dump(X_train.dtypes, fh)\n",
    "    \n",
    "joblib.dump(pipeline, os.path.join(TMP_DIR, 'pipeline.pickle')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91d0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
