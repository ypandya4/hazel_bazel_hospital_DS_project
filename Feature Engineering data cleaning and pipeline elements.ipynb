{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91d16f2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fff49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import math\n",
    "import requests\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "from uuid import uuid4\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, power_transform, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (precision_score,\n",
    "                            recall_score,\n",
    "                            f1_score,\n",
    "                            accuracy_score,\n",
    "                            roc_auc_score,\n",
    "                            confusion_matrix,\n",
    "                            ConfusionMatrixDisplay,\n",
    "                            make_scorer,\n",
    "                            RocCurveDisplay,\n",
    "                            auc,\n",
    "                            roc_curve)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bacc6b7",
   "metadata": {},
   "source": [
    "# Custom transformer imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb32c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP preprocessor which assigns categories and compresses some code\n",
    "from custom_transformers.preprocessor import ColumnConverter\n",
    "\n",
    "# WIP ordinal category preprocessor\n",
    "from custom_transformers.custom_ordinal_encoder import custom_oe\n",
    "\n",
    "#WIP column selector\n",
    "from custom_transformers.featureselector import SelectColumns\n",
    "\n",
    "# WIP onehot category preprocessor\n",
    "from custom_transformers.custom_onehot_encoder import custom_one_hot\n",
    "\n",
    "# WIP onehot category preprocessor\n",
    "from custom_transformers.custom_impute_scale import custom_impute_scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da63fd8",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4102f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    df = pd.read_csv(os.path.join(\"data\", \"train_data.csv\"))\n",
    "    return df\n",
    "\n",
    "data_train = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ec538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_index(df, indexcol: str):\n",
    "    _df = df.copy()\n",
    "    _df = _df.set_index(indexcol)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaaf75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target(df, target: str):\n",
    "    _df = df.copy()\n",
    "    _df[target] = np.where(_df[target]== 'Yes', True, False)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8045ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processgender(df):\n",
    "    _df = df.copy()\n",
    "    _df['gender'] = _df['gender'].str.lower()\n",
    "    valid_genders = ['male', 'female']\n",
    "    _df.loc[~(_df['gender'].isin(valid_genders)), 'age'] = 'unknown'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402e6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processrace(df):\n",
    "    _df = df.copy()\n",
    "    _df['race'] = _df['race'].str.lower().str.lstrip().str[0:3]\n",
    "    black = ['afr', 'bla']\n",
    "    white = ['cau', 'whi', 'eur']\n",
    "    hispanic = ['his', 'lat']\n",
    "    asian = ['asi']\n",
    "    race_options = black+white+hispanic+asian\n",
    "    _df.loc[~(_df['race'].isin(race_options)), 'race'] = 'unknown/other'\n",
    "    _df.loc[(_df['race'].isin(black)), 'race'] = 'black'\n",
    "    _df.loc[(_df['race'].isin(white)), 'race'] = 'white'\n",
    "    _df.loc[(_df['race'].isin(hispanic)), 'race'] = 'hispanic'\n",
    "    _df.loc[(_df['race'].isin(asian)), 'race'] = 'asian'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c7a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insurancestatus(df):\n",
    "    _df = testdf.copy()\n",
    "    _df.payer_code = _df.payer_code.where(_df.payer_code != '?')\n",
    "    _df.payer_code = _df.payer_code.fillna(value='unknown')\n",
    "    _df.loc[(_df['payer_code'] == 'SP'), 'payer_code'] == 'uninsured'\n",
    "    _df.loc[~(_df['payer_code'].isin(['SP', 'unknown'])), 'payer_code'] = 'insured'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9cef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processadmissiontype(df):\n",
    "    _df = df.copy()\n",
    "    _df.loc[(_df['admission_type_code'].isin([5, 6, 8])), 'admission_type_code'] = 'n/a'\n",
    "    _df.loc[(_df['admission_type_code'] == 1), 'admission_type_code'] = 'emergency'\n",
    "    _df.loc[(_df['admission_type_code'] == 2), 'admission_type_code'] = 'urgent'\n",
    "    _df.loc[(_df['admission_type_code'] == 3), 'admission_type_code'] = 'elective'\n",
    "    _df.loc[(_df['admission_type_code'] == 4), 'admission_type_code'] = 'newborn'\n",
    "    _df.loc[(_df['admission_type_code'] == 7), 'admission_type_code'] = 'trauma'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f12c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processdischargecode(df):\n",
    "    _df = df.copy()\n",
    "\n",
    "    home = [1]\n",
    "    left_ama = [7]\n",
    "    hospice = [13, 14]\n",
    "    transferred = [2, 3, 4, 5, 9, 10, 15, 22, 23, 24, 27, 28, 29]\n",
    "    died = [11, 19, 20, 21]\n",
    "    for_outpatient_services = [12, 16, 17]\n",
    "    home_services = [6, 8]\n",
    "    all_cats = home+left_ama+hospice+transferred+died+for_outpatient_services+home_services\n",
    "\n",
    "    _df.loc[~(_df['discharge_disposition_code'].isin(all_cats)), 'discharge_disposition_code'] = 'unknown'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(home)), 'discharge_disposition_code'] = 'discharged_home'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(left_ama)), 'discharge_disposition_code'] = 'left_ama'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(hospice)), 'discharge_disposition_code'] = 'discharged_hospice'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(transferred)), 'discharge_disposition_code'] = 'transferred_inpatient'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(died)), 'discharge_disposition_code'] = 'expired'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(for_outpatient_services)), 'discharge_disposition_code'] = 'transferred_outpatient'\n",
    "    _df.loc[(_df['discharge_disposition_code'].isin(home_services)), 'discharge_disposition_code'] = 'home_care'\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3018352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processspecializations(df):\n",
    "    _df = df.copy()\n",
    "    _df['medical_specialty'] = _df['medical_specialty'].str.lower()\n",
    "    counts = pd.DataFrame(_df.medical_specialty.value_counts())\n",
    "    df_mask = counts['medical_specialty']>=100\n",
    "    selected_specialties = counts[df_mask]\n",
    "    selected_specialties = selected_specialties.index.to_list()\n",
    "    _df.loc[~(_df['medical_specialty'].isin(selected_specialties)), 'medical_specialty'] = 'other'\n",
    "    _df.loc[(_df['medical_specialty'] == '?'), 'medical_specialty'] = 'unknown'\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89231c2b",
   "metadata": {},
   "source": [
    "# Function to test if we satisfied requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521ec1c",
   "metadata": {},
   "source": [
    "The first step will make a copy of the X_test and apply the custom converter for the columns - it will update the categories we are interested in (avoid duplicates etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1b0a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_no_discrimination(X_test,\n",
    "                             y_true,\n",
    "                             y_pred,\n",
    "                             sensitive_columns = [],\n",
    "                             max_diff=0.1,\n",
    "                             average='weighted'):    \n",
    "    # Use this as a template to get output:\n",
    "    #f1_scores, diff, is_satisfied  = verify_no_discrimination(X_test,\n",
    "    #                                                          y_test,\n",
    "    #                                                          y_pred,\n",
    "    #                                                          sensitive_column=['Self-defined ethnicity', 'race'] etc\n",
    "    #                                                          max_diff=0.15 )\n",
    "    #f1_scores, diff, is_satisfied\n",
    "    \n",
    "    _df = X_test.copy()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    cc = ColumnConverter()\n",
    "    _df = cc.fit_transform(_df)\n",
    "    \n",
    "    for column in sensitive_columns:  \n",
    "        sensitive_classes = _df[column].unique()\n",
    "        is_satisfied = True\n",
    "        f1_scores = {}\n",
    "        \n",
    "        for sensitive_class in sensitive_classes:\n",
    "            mask = (_df[column] == sensitive_class)\n",
    "            if mask.sum():\n",
    "                f1_scores[sensitive_class] = f1_score(y_true[mask],\n",
    "                                                      y_pred[mask],\n",
    "                                                      pos_label=1,\n",
    "                                                      labels=np.unique(y_pred[mask]))\n",
    "        \n",
    "        diff = np.max(list(f1_scores.values())) - np.min(list(f1_scores.values()))\n",
    "        if diff > max_diff:\n",
    "            is_satisfied = False\n",
    "        \n",
    "        results[column] = [f1_scores, diff, is_satisfied]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84447972",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517e7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'readmitted'\n",
    "index_col = 'admission_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "787600aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_train_data()\n",
    "data_train = assign_index(data_train, index_col)\n",
    "data_train = build_target(data_train, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97871020",
   "metadata": {},
   "source": [
    "# Simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51f32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all features (n=numerical, uc=unordered actegory, oc=ordered category, b=boolean)\n",
    "\n",
    "all_features = ['patient_id', #identifier\n",
    "                'race', #uc\n",
    "                'gender', #uc\n",
    "                'age', #oc\n",
    "                'weight', #oc               \n",
    "                'admission_type_code', #uc\n",
    "                'discharge_disposition_code', #uc\n",
    "                'admission_source_code', #uc\n",
    "                'time_in_hospital', #n\n",
    "                'payer_code', #uc\n",
    "                'medical_specialty', #uc\n",
    "                'has_prosthesis', #b\n",
    "                'complete_vaccination_status', #uc\n",
    "                'num_lab_procedures', #n\n",
    "                'num_procedures', #n\n",
    "                'num_medications', #n\n",
    "                'number_outpatient', #n\n",
    "                'number_emergency', #n\n",
    "                'number_inpatient', #n\n",
    "                'diag_1', #uc\n",
    "                'diag_2', #uc\n",
    "                'diag_3', #uc\n",
    "                'number_diagnoses', #n\n",
    "                'blood_type', #uc\n",
    "                'hemoglobin_level', #n\n",
    "                'blood_transfusion', #b\n",
    "                'max_glu_serum', #oc\n",
    "                'A1Cresult', #oc\n",
    "                'diuretics', #b\n",
    "                'insulin', #b\n",
    "                'change', #b\n",
    "                'diabetesMed'] #b]\n",
    "\n",
    "num_features = ['time_in_hospital', \n",
    "                'num_lab_procedures',\n",
    "                'num_procedures',\n",
    "                'num_medications',\n",
    "                'number_outpatient',\n",
    "                'number_emergency',\n",
    "                'number_inpatient',\n",
    "                'number_diagnoses',\n",
    "                'hemoglobin_level']\n",
    "\n",
    "bool_features = ['has_prosthesis',\n",
    "                 'blood_transfusion',\n",
    "                 'diuretics',\n",
    "                 'insulin',\n",
    "                 'change',\n",
    "                 'diabetesMed']\n",
    "\n",
    "cat_features = ['race',\n",
    "                'gender',\n",
    "                'admission_type_code', \n",
    "                'discharge_disposition_code',\n",
    "                'admission_source_code', \n",
    "                'payer_code',\n",
    "                'medical_specialty',\n",
    "                'diag_1',\n",
    "                'diag_2',\n",
    "                'diag_3',\n",
    "                'blood_type']\n",
    "\n",
    "ord_cat_features = ['age',\n",
    "                    'weight',\n",
    "                    'max_glu_serum',\n",
    "                    'A1Cresult',\n",
    "                    'complete_vaccination_status',]\n",
    "\n",
    "# missing features: date of admission and date of release"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061244a",
   "metadata": {},
   "source": [
    "### Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cdd6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to boolean\n",
    "\n",
    "# We have a small portion kept aside because of our random undersampling approach where we lose a lot of train data \n",
    "df_train, df_test = train_test_split(data_train, test_size=0.1, random_state=42, stratify=data_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8aa1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(target, axis=1)\n",
    "y_train = df_train[target]\n",
    "X_test = df_test.drop(target, axis=1)\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2caf2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['time_in_hospital', \n",
    "                     'num_lab_procedures',\n",
    "                     'num_procedures',\n",
    "                     'num_medications',\n",
    "                     'number_outpatient',\n",
    "                     'number_emergency',\n",
    "                     'number_inpatient',\n",
    "                     'number_diagnoses',\n",
    "                     'hemoglobin_level',\n",
    "                     \n",
    "                     'has_prosthesis',\n",
    "                     'blood_transfusion',\n",
    "                     'diuretics',\n",
    "                     'insulin',\n",
    "                     'change',\n",
    "                     'diabetesMed',\n",
    "                     \n",
    "                     'race',\n",
    "                     'gender',\n",
    "                     'admission_type_code', \n",
    "                     'discharge_disposition_code',\n",
    "                     'admission_source_code', \n",
    "                     'payer_code',\n",
    "                     'medical_specialty',\n",
    "                     'complete_vaccination_status',\n",
    "                     'blood_type',\n",
    "                     \n",
    "                     'max_glu_serum',\n",
    "                     'A1Cresult',\n",
    "                     'age',\n",
    "                     'weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7365df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = [feat for feat in selected_features if feat in num_features]\n",
    "cat_feats = [feat for feat in selected_features if feat in cat_features+bool_features+ord_cat_features]\n",
    "bool_feats = [feat for feat in selected_features if feat in bool_features]\n",
    "ord_cat_feats = [feat for feat in selected_features if feat in ord_cat_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566aed0",
   "metadata": {},
   "source": [
    "# Pipeline 1 - just numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff1a932",
   "metadata": {},
   "source": [
    "#### Numbers processed in a custom transformer (part of the ColumnConverter) - will be placed into a separate file\n",
    "1. Missing values imputed using KNNImputer\n",
    "2. Values have a significant skew, so RobustScaler was selected to avoid outliers having hige impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3f00e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['time_in_hospital', \n",
    "                'num_lab_procedures',\n",
    "                'num_procedures',\n",
    "                'num_medications',\n",
    "                'number_outpatient',\n",
    "                'number_emergency',\n",
    "                'number_inpatient',\n",
    "                'number_diagnoses',\n",
    "                'hemoglobin_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cd2fc36",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a9adee660add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 393\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/bootcamp/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    SelectColumns(cols=num_feats),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    RandomForestClassifier(max_depth=10, class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# To use on other cells\n",
    "print(\"f1 score: %s\" % (f1_score(y_test, y_pred)))\n",
    "print(\"recall score: %s\" % (recall_score(y_test, y_pred)))\n",
    "print(\"precision score: %s\" % (precision_score(y_test, y_pred)))\n",
    "print(\"discrimination results:\")\n",
    "#verify_no_discrimination(X_test=X_test, y_true=y_test, y_pred=y_pred, sensitive_columns = ['medical_specialty', 'payer_code','gender','race'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7d70e",
   "metadata": {},
   "source": [
    "# Pipeline 2 - adding the binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_features = ['has_prosthesis',\n",
    "                 'blood_transfusion',\n",
    "                 'diuretics',\n",
    "                 'insulin',\n",
    "                 'change',\n",
    "                 'diabetesMed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f58f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    SelectColumns(cols=num_feats+bool_feats),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    RandomForestClassifier(max_depth=10, class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# To use on other cells\n",
    "print(\"f1 score: %s\" % (f1_score(y_test, y_pred)))\n",
    "print(\"recall score: %s\" % (recall_score(y_test, y_pred)))\n",
    "print(\"precision score: %s\" % (precision_score(y_test, y_pred)))\n",
    "print(\"discrimination results:\")\n",
    "verify_no_discrimination(X_test=X_test, y_true=y_test, y_pred=y_pred, sensitive_columns = ['medical_specialty', 'payer_code','gender','race'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff16d0",
   "metadata": {},
   "source": [
    "# Pipeline 3 - adding ordered categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a4fc2",
   "metadata": {},
   "source": [
    "1. added age, weight, max_glu_serum, A1Cresult, and also encoded vaccination status here\n",
    "2. also did some playing around with the model options for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a351b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_cat_features = ['age',\n",
    "                    #'weight',\n",
    "                    'max_glu_serum',\n",
    "                    'A1Cresult',\n",
    "                    'complete_vaccination_status',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5215a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    custom_oe(),\n",
    "    SelectColumns(cols=num_feats+bool_feats+ord_cat_feats),\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    RandomForestClassifier(max_depth=10,\n",
    "                           class_weight=\"balanced\",\n",
    "                           random_state=42,\n",
    "                           n_jobs=-1,\n",
    "                           criterion = 'entropy',\n",
    "                           bootstrap = False))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# To use on other cells\n",
    "print(\"f1 score: %s\" % (f1_score(y_test, y_pred)))\n",
    "print(\"recall score: %s\" % (recall_score(y_test, y_pred)))\n",
    "print(\"precision score: %s\" % (precision_score(y_test, y_pred)))\n",
    "print(\"discrimination results:\")\n",
    "#verify_no_discrimination(X_test=X_test, y_true=y_test, y_pred=y_pred, sensitive_columns = ['medical_specialty', 'payer_code','gender','race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3fb5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, labels = pipeline.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline.classes_)\n",
    "disp.plot(cmap=\"OrRd\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792ce3a",
   "metadata": {},
   "source": [
    "Trying gradient boosting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37c711",
   "metadata": {},
   "source": [
    "# Adding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda46ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['race', #done\n",
    "                'gender', #done\n",
    "                'admission_type_code', #done \n",
    "                'discharge_disposition_code', #done\n",
    "                'admission_source_code', #done \n",
    "                'payer_code', #done (now the insurance column)\n",
    "                'medical_specialty', #done (any specialty over 100 - lets see how bad it gets)\n",
    "                'diag_1',\n",
    "                'diag_2',\n",
    "                'diag_3',\n",
    "                'blood_type'\n",
    "               ] #dropping blood type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29840f",
   "metadata": {},
   "source": [
    "1. Will drop blood type - too many inconsistencies and not feasible to guess\n",
    "1. Does admission type and code have a role?\n",
    "1. Race, gender can be encoded\n",
    "1. Payer code 'SP' is an indicator of uninsured patients - what to do with '?' should we make 3 categories?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d7c778",
   "metadata": {},
   "source": [
    "### Processing Diagnoses:\n",
    "1. High cardinality (and possibly redundant information due to overlap with the speecialty?)\n",
    "1. Used encoding system to try to group (by large groups of diagnoses - definetely losing a lot of resolution here):\n",
    "    1. Diagnostic_categories = ['infection', #001-139\n",
    "                         'neoplasms', #140-239\n",
    "                         'endocrine_nutritional_metabolic_immune', #240-279\n",
    "                         'blood', #280-289\n",
    "                         'mental', #290-319\n",
    "                         'nervous_system', #320-389\n",
    "                         'circulatory', #390-459\n",
    "                         'respiratory', #460-519\n",
    "                         'digestive', #520-579\n",
    "                         'genitourinary', #580-629\n",
    "                         'pregnancy', #630-679\n",
    "                         'skin', #680-709\n",
    "                         'musculoskeletal', #710-739\n",
    "                         'congenital', #740-759\n",
    "                         'perinatal', #760-779\n",
    "                         'ill_defined', #780-799\n",
    "                         'injury_poisoning', #800-899, also E800-E999\n",
    "                         'supplemental' #V01-V89\n",
    "                        ]\n",
    "1. Selecting most common codes and encoding the others\n",
    "1. Next step may be to use encoding from RTF files and try tfidf vectorizer\n",
    "1. Grouping codes by likelihood to cause readmission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055d9bc",
   "metadata": {},
   "source": [
    "#### Selecting most common diagnostic codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "infection = [str(code) for code in list(range(1, 140))]\n",
    "neoplasms = [str(code) for code in list(range(141, 240))]\n",
    "endocrine_nutritional_metabolic_immune = [str(code) for code in list(range(241, 280))]\n",
    "blood = [str(code) for code in list(range(280, 290))]\n",
    "mental = [str(code) for code in list(range(290, 320))]\n",
    "nervous_system = [str(code) for code in list(range(320, 390))]\n",
    "circulatory = [str(code) for code in list(range(390, 460))]\n",
    "respiratory = [str(code) for code in list(range(460, 520))]\n",
    "digestive = [str(code) for code in list(range(520, 580))]\n",
    "genitourinary = [str(code) for code in list(range(580, 630))]\n",
    "pregnancy = [str(code) for code in list(range(630, 680))]\n",
    "skin = [str(code) for code in list(range(680, 710))]\n",
    "musculoskeletal = [str(code) for code in list(range(710, 740))]\n",
    "congenital = [str(code) for code in list(range(740, 760))]\n",
    "perinatal = [str(code) for code in list(range(760, 780))]\n",
    "ill_defined = [str(code) for code in list(range(780, 800))]\n",
    "injury_poisoning = [str(code) for code in list(range(800, 900))] + ['e'+str(code) for code in list(range(800, 900))]\n",
    "supplemental = ['v'+str(code) for code in list(range(1, 90))]\n",
    "\n",
    "all_codes = infection + neoplasms + endocrine_nutritional_metabolic_immune + blood + mental+ nervous_system + circulatory + respiratory + digestive + genitourinary + pregnancy + skin + musculoskeletal+ congenital+ perinatal+ ill_defined+ injury_poisoning+ supplemental \n",
    "\n",
    "_df = X_train.copy()[['diag_1', 'diag_2', 'diag_3']]\n",
    "columns = ['diag_1', 'diag_2', 'diag_3']\n",
    "for col in columns:\n",
    "    _df[col] = _df[col].str.lower().str[0:3]\n",
    "    _df[col] = _df[col].fillna(value='unknown')\n",
    "    _df.loc[~(_df[col].isin(all_codes)), col] = 'unknown'\n",
    "    \n",
    "    top100 = _df[col].value_counts().head(100).index.tolist()\n",
    "    \n",
    "    _df.loc[(_df[col].isin(infection)) & ~(_df[col].isin(top100)), col] = 'infection'\n",
    "    _df.loc[(_df[col].isin(neoplasms))& ~(_df[col].isin(top100)), col] = 'neoplasms'\n",
    "    _df.loc[(_df[col].isin(endocrine_nutritional_metabolic_immune))& ~(_df['diag_1'].isin(top100)), col] = 'endocrine_nutritional_metabolic_immune'\n",
    "    _df.loc[(_df[col].isin(blood))& ~(_df[col].isin(top100)), col] = 'blood'\n",
    "    _df.loc[(_df[col].isin(mental))& ~(_df[col].isin(top100)), col] = 'mental'\n",
    "    _df.loc[(_df[col].isin(nervous_system))& ~(_df[col].isin(top100)), col] = 'nervous_system'\n",
    "    _df.loc[(_df[col].isin(circulatory))& ~(_df[col].isin(top100)), col] = 'circulatory'\n",
    "    _df.loc[(_df[col].isin(respiratory))& ~(_df[col].isin(top100)), col] = 'respiratory'\n",
    "    _df.loc[(_df[col].isin(digestive))& ~(_df[col].isin(top100)), col] = 'digestive'\n",
    "    _df.loc[(_df[col].isin(genitourinary))& ~(_df[col].isin(top100)), col] = 'genitourinary'\n",
    "    _df.loc[(_df[col].isin(pregnancy))& ~(_df[col].isin(top100)), col] = 'pregnancy'\n",
    "    _df.loc[(_df[col].isin(skin))& ~(_df[col].isin(top100)), col] = 'skin'\n",
    "    _df.loc[(_df[col].isin(musculoskeletal))& ~(_df[col].isin(top100)), col] = 'musculoskeletal'\n",
    "    _df.loc[(_df[col].isin(congenital))& ~(_df[col].isin(top100)), col] = 'congenital'\n",
    "    _df.loc[(_df[col].isin(perinatal))& ~(_df[col].isin(top100)), col] = 'perinatal'\n",
    "    _df.loc[(_df[col].isin(ill_defined))& ~(_df[col].isin(top100)), col] = 'ill_defined'\n",
    "    _df.loc[(_df[col].isin(injury_poisoning))& ~(_df[col].isin(top100)), col] = 'injury_poisoning'\n",
    "    _df.loc[(_df[col].isin(supplemental))& ~(_df[col].isin(top100)), col] = 'supplemental'\n",
    "    _df.loc[(_df[col].isin(infection))& ~(_df[col].isin(top100)), col] = 'infection'\n",
    "            \n",
    "    _df[col] = _df[col].astype('category')\n",
    "    \n",
    "_df = X_train.copy()[['diag_1', 'diag_2', 'diag_3']]\n",
    "columns = ['diag_1', 'diag_2', 'diag_3']\n",
    "top100 = {}\n",
    "for col in columns:\n",
    "    _df[col] = _df[col].str.lower().str[0:3]\n",
    "    _list = _df[col].value_counts().head(100).index.tolist()\n",
    "    top100[col] = _list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908eee5",
   "metadata": {},
   "source": [
    "Using this and adapting it in the preprocessing did not improve the model (made it worse in fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a03af",
   "metadata": {},
   "source": [
    "#### Grouping the diagnostic codes by probability of readmission for ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e56485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _df = df_train.copy()\n",
    "# columns = ['diag_1', 'diag_2', 'diag_3']\n",
    "# diag_readmission = {}\n",
    "# for col in columns:\n",
    "#     _df[col] = _df[col].str.lower().str[0:3]\n",
    "#     _df[col] = _df[col].fillna(value='unknown')\n",
    "#     _df.loc[~(_df[col].isin(all_codes)), col] = 'unknown'\n",
    "    \n",
    "#     total_readmission = float(_df.pivot_table(values=['readmitted'],\n",
    "#                                               index=col,\n",
    "#                                               aggfunc=np.sum)\n",
    "#                               .sum()\n",
    "#                               .values)\n",
    "#     readmission_rate = (total_readmission)/(_df[col].value_counts().sum())*100\n",
    "    \n",
    "#     data = _df.pivot_table(values=['readmitted'], index=col, aggfunc=np.mean)*100\n",
    "    \n",
    "#     _dict = {'very_low': data[(data['readmitted']<5)].index.tolist(),\n",
    "#              'low': data[(data['readmitted']>=5) & (data['readmitted']<15)].index.tolist(),\n",
    "#              'medium': data[(data['readmitted']>=15) & (data['readmitted']<25)].index.tolist(),\n",
    "#              'medium_high': data[(data['readmitted']>=25) & (data['readmitted']<50)].index.tolist(),\n",
    "#              'high': data[(data['readmitted']>=50)].index.tolist()}\n",
    "    \n",
    "#     diag_readmission[col] = _dict\n",
    "    \n",
    "# print(diag_readmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89535493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _df = X_train.copy()\n",
    "\n",
    "# all_codes = [str(code) for code in list(range(1, 900))] + ['e'+str(code) for code in list(range(800, 900))] +['v'+str(code) for code in list(range(1, 90))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eafb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in columns:\n",
    "#     _df[col] = _df[col].str.lower().str[0:3]\n",
    "#     _df[col] = _df[col].fillna(value='unknown')\n",
    "#     _df.loc[~(_df[col].isin(all_codes)), col] = 'unknown'\n",
    "    \n",
    "#     _dict = diag_readmission[col]\n",
    "    \n",
    "#     _df.loc[(_df[col].isin(_dict['very_low'])), col] = 'very_low'\n",
    "#     _df.loc[(_df[col].isin(_dict['low'])), col] = 'low'\n",
    "#     _df.loc[(_df[col].isin(_dict['medium'])), col] = 'medium'\n",
    "#     _df.loc[(_df[col].isin(_dict['medium_high'])), col] = 'medium_high'\n",
    "#     _df.loc[(_df[col].isin(_dict['high'])), col] = 'high'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649665e4",
   "metadata": {},
   "source": [
    "### Vectorizing text development space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ed8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_icd9():\n",
    "    #load the data\n",
    "    icd9_codes = pd.read_csv('data/icd9.txt', sep='\\t', dtype={0:\"str\"}, header=None)\n",
    "    icd9_codes = icd9_codes.rename({0:'all_data'}, axis=1)\n",
    "    \n",
    "    #split the string to code and data\n",
    "    icd9_codes = icd9_codes['all_data'].str.split(' ', 1, expand=True)\n",
    "    icd9_codes = icd9_codes.rename({0:\"code\", 1:\"description\"}, axis=1)\n",
    "    icd9_codes['code'] = icd9_codes['code'].str.lstrip('0').str[0:3].str.lower()\n",
    "    icd9_codes['description'] = icd9_codes['description'].str.strip().str.lower()\n",
    "    \n",
    "    #make the index the code to facilitate lookup\n",
    "    icd9_codes = icd9_codes.set_index('code')\n",
    "    \n",
    "    return icd9_codes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58745d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_diagnosis(df):\n",
    "    _df = df.copy()\n",
    "    icd9_codes = load_icd9()\n",
    "    for column in ['diag_1', 'diag_2', 'diag_3']:\n",
    "        #encode the columns and map\n",
    "        _df[column] = _df[column].str[0:3].str.lower()\n",
    "        _df = _df.replace({column: (icd9_codes['description'])})\n",
    "        _df[column] = _df[column].fillna(value='unknown')\n",
    "        \n",
    "        #vectorizer\n",
    "        vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "        data_vect = vectorizer.fit_transform(_df[column])\n",
    "        \n",
    "        #pca\n",
    "        pca = PCA(n_components=5, random_state=42)\n",
    "        data_pca = pca.fit_transform(data_vect.toarray())\n",
    "        \n",
    "        #add the top 5 components\n",
    "        for i in list(range(0, 5)):\n",
    "            _df['{col}_c{c}'.format(col=column, c=i)] = (data_pca[:, i]).tolist()\n",
    "        \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = data_train.copy()[['diag_1', 'diag_2', 'diag_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39426be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = process_diagnosis(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d562f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data['readmitted'] = data_train['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e597a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = testing_data[testing_data['readmitted'] == True]\n",
    "no = testing_data[testing_data['readmitted'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f098d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "no.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2cf372",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(no['diag_3_c0'], no['diag_3_c2'], s=10, c='r', marker=\"o\", label='Not readmitted')\n",
    "ax1.scatter(yes['diag_3_c0'], yes['diag_3_c2'], s=10, c='b', marker=\"s\", label='Readmitted')\n",
    "plt.legend(loc='upper left');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9261f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050c66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise notimplementederror"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7804866",
   "metadata": {},
   "source": [
    "# A quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## put this into a custom transformer please\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #('num', numeric_transformer, num_feats),\n",
    "        ('cat', categorical_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    SelectColumns(cols=num_feats+bool_feats+ord_cat_feats+cat_features),\n",
    "    custom_oe(),\n",
    "    preprocessor,\n",
    "    RandomForestClassifier(max_depth=10, class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"f1 score: %s\" % (f1_score(y_test, y_pred)))\n",
    "print(\"recall score: %s\" % (recall_score(y_test, y_pred)))\n",
    "print(\"precision score: %s\" % (precision_score(y_test, y_pred)))\n",
    "print(\"discrimination results:\")\n",
    "verify_no_discrimination(X_test=X_test, y_true=y_test, y_pred=y_pred, sensitive_columns = ['medical_specialty', 'payer_code','gender','race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ac463",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, labels = pipeline.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline.classes_)\n",
    "disp.plot(cmap=\"OrRd\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a39c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=None)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnConverter(),\n",
    "    SelectColumns(cols=num_feats+bool_feats+ord_cat_feats+cat_features),\n",
    "    custom_oe(),\n",
    "    preprocessor,\n",
    "    GradientBoostingClassifier(learning_rate=.1,\n",
    "                               n_estimators=100,\n",
    "                               subsample=0.2,\n",
    "                               n_iter_no_change=10,\n",
    "                               max_features = None,\n",
    "                               random_state=42)\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"f1 score: %s\" % (f1_score(y_test, y_pred)))\n",
    "print(\"recall score: %s\" % (recall_score(y_test, y_pred)))\n",
    "print(\"precision score: %s\" % (precision_score(y_test, y_pred)))\n",
    "print(\"discrimination results:\")\n",
    "verify_no_discrimination(X_test=X_test, y_true=y_test, y_pred=y_pred, sensitive_columns = ['medical_specialty', 'payer_code','gender','race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred, labels = pipeline.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline.classes_)\n",
    "disp.plot(cmap=\"OrRd\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=None)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7414156a",
   "metadata": {},
   "source": [
    "# Output files (pickling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMP_DIR = '/tmp'\n",
    "# with open(os.path.join(TMP_DIR, \"columns.json\"), 'w') as fh:\n",
    "#     json.dump(X_train.columns.tolist(), fh)\n",
    "\n",
    "# with open(os.path.join(TMP_DIR, \"dtypes.pickle\"), 'wb') as fh:\n",
    "#     pickle.dump(X_train.dtypes, fh)\n",
    "    \n",
    "# joblib.dump(pipeline, os.path.join(TMP_DIR, 'pipeline.pickle')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91d0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
